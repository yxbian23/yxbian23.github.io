import{_ as m,o as s,c as n,a as e,F as p,r as h,t as r,b,w as g,T as w,d as v,e as _,n as u,G as f,f as l,p as y,g as I}from"./index-860635d1.js";import{_ as P}from"./li2024uni-isp-dataset-86b1a595.js";const S="/pub-images/li2024uni-isp-cover.jpg",x="/pub-images/li2024uni-isp-model.jpg",C="/pub-images/uni-isp/SelfCam-InverseISP.jpg",R="/pub-images/uni-isp/SelfCam-ForwardISP.jpg",k="/pub-images/uni-isp/PhotoAppearanceTrans-Cmp.jpg",j="/pub-images/uni-isp/Interpolation3-Full.jpg",M="/pub-images/uni-isp/SpliceDetection2.jpg",U="/pub-videos/li2024uni-isp-video.mp4";const i=d=>(y("data-v-1b0781a9"),d=d(),I(),d),L={class:"project-content"},T={class:"project-content-margin",style:{width:"84%"}},F=v('<div style="text-align:center;" data-v-1b0781a9><h1 data-v-1b0781a9>Uni-ISP: Unifying the Learning of ISPs from Multiple Cameras</h1><p data-v-1b0781a9><a href="#" data-v-1b0781a9>Lingen Li</a>, Mingde Yao, Xingyu Meng, Muquan Yu, Tianfan Xue, and Jinwei Gu </p><p data-v-1b0781a9> The Chinese University of Hong Kong </p><img src="'+S+'" style="width:100%;max-width:1000px;" data-v-1b0781a9><br data-v-1b0781a9><p style="text-align:justify;width:98%;padding:0 1% 0 1%;" data-v-1b0781a9> We propose <strong data-v-1b0781a9>Uni-ISP</strong>, a model that unifies the learning of inverse and forward ISP behaviors of multiple cameras simultaneously. By leveraging the shared characteristics across various camera ISPs, our method can achieve higher performance in inverse and forward ISP (A) compared to previously learned ISP methods tailored for only one camera separately. Meanwhile, the device-aware property of the Uni-ISP enables new cross-camera ISP applications for a learned ISP model, including photographic appearance transfer (B and C), inter/extrapolation (D), and zero-shot image forensics (E and F). </p></div><h2 data-v-1b0781a9>Method</h2><div style="text-align:center;" data-v-1b0781a9><img src="'+x+'" style="width:100%;max-width:1000px;" data-v-1b0781a9><br data-v-1b0781a9><p style="text-align:justify;width:98%;padding:0 1% 0 1%;" data-v-1b0781a9> The model design of Uni-ISP. Uni-ISP contains two modules, the inverse ISP module and the forward ISP module. Both two modules share the same structure. For visual simplicity, we draw the inverse ISP moduleas a thumbnail, whose inner structure is the same as the forward ISP module. The device-aware embeddings are optimizable parameters and will be selected to interact with the bottleneck features via the DEIM during the training or inference. </p></div><h2 data-v-1b0781a9>New Dataset: FiveCam</h2><div style="text-align:center;" data-v-1b0781a9><img src="'+P+'" style="width:100%;max-width:1000px;" data-v-1b0781a9><br data-v-1b0781a9><p style="text-align:justify;width:98%;padding:0 1% 0 1%;" data-v-1b0781a9> The preview of 3 scenes in our new dataset (left) and our capture devices (right). Each scene includes synchronized sRGB-Raw pairs of five smartphone cameras: Apple iPhone 14 Pro Max, Google Pixel 6 Pro, Huawei P40, Samsung Galaxy S20, and Xiaomi Mi 12. The raw images are visualized as XYZ images here, which can be converted back to raw without loss.</p></div><h2 data-v-1b0781a9>Applications</h2><h3 data-v-1b0781a9>1. Inverse and Forward ISP</h3><div class="centering" data-v-1b0781a9><div class="g-card" style="width:95%;max-width:800px;padding:15px;" data-v-1b0781a9><strong data-v-1b0781a9>Inverse ISP</strong><p data-v-1b0781a9></p><img style="width:100%;" src="'+C+'" data-v-1b0781a9></div><p data-v-1b0781a9></p><div class="g-card" style="width:95%;max-width:800px;padding:15px;" data-v-1b0781a9><strong data-v-1b0781a9>Forward ISP</strong><p data-v-1b0781a9></p><img style="width:100%;" src="'+R+'" data-v-1b0781a9></div></div><h4 data-v-1b0781a9>Other Results - HDR Rendering:</h4><p data-v-1b0781a9>Based on the inverse ISP ability learned by our model, we can convert a given sRGB back to the linear color space, and sythesize exposure stack to render HDR images.</p>',10),D={class:"centering"},V={class:"g-title-container"},B={class:"g-title",style:{color:"white","font-weight":"bold"}},z=i(()=>e("br",null,null,-1)),G=i(()=>e("span",{class:"g-sub-title",style:{color:"white"}}," Sample Scene ",-1)),X=i(()=>e("div",{class:"centering"},[e("p",null,[e("i",{class:"fa fa-mouse-pointer"}),l(),e("b",null,"Click on a tag below"),l(" to switch among LDR input, HDR rendering results of each method, and the ground truth.")])],-1)),A={class:"centering"},H=["onClick"],N={class:"centering"},Y=i(()=>e("br",null,null,-1)),E=["src"],$=v('<h3 data-v-1b0781a9>2. Photographic Appearance Transfer</h3><div class="centering" data-v-1b0781a9><img class="g-card" style="width:95%;max-width:800px;padding:15px;" src="'+k+'" data-v-1b0781a9><p data-v-1b0781a9>This transfer ability can be extended to video without explicit temporal design. Please refer to the video section below.</p></div><h3 data-v-1b0781a9>3. Photographic Appearance Interpolation</h3><div class="centering" data-v-1b0781a9><img class="g-card" style="width:95%;max-width:800px;padding:15px;" src="'+j+'" data-v-1b0781a9></div><h3 data-v-1b0781a9>4. Zero-shot Image Forensics</h3><p data-v-1b0781a9>Uni-ISP has bonus ability in zero-shot image forensics, including source camera identification and image splice detection, without any trainig on forensics datasets. Please refer to the paper for more details. Here we show an example of image splice detection. A fake object is integrated into each real photo using Poisson image editing, with darker regions in the result indicating suspected modifications.</p><div class="centering" data-v-1b0781a9><img class="g-card" style="width:95%;max-width:500px;padding:15px;" src="'+M+'" data-v-1b0781a9></div><h2 data-v-1b0781a9>Video</h2>',8),O={key:0},Z=i(()=>e("p",null,"Click on the button to view the short introduction video of Uni-ISP. It might take a while to load this video.",-1)),q={style:{"text-align":"center","font-size":"x-large"}},J=i(()=>e("i",{class:"fa fa-play"},null,-1)),K={key:1,style:{"text-align":"center"}},W=i(()=>e("video",{class:"g-card",id:"media",src:U,controls:"",autoplay:"",style:{width:"100%","max-width":"1000px"}},null,-1)),Q=[W],ee=i(()=>e("h2",null,"Citation",-1)),ae=i(()=>e("p",null,"ðŸ˜Š Consider citing this paper if you found our work/dataset useful in your research. ",-1)),ie=i(()=>e("div",{class:"code"},[e("pre",null,`@article{li2024uni,
  title={Uni-ISP: Unifying the Learning of ISPs from Multiple Cameras},
  author={Li, Lingen and Yao, Mingde and Meng, Xingyu and Yu, Muquan and Xue, Tianfan and Gu, Jinwei},
  journal={arXiv preprint arXiv:2406.01003},
  year={2024}
}`)],-1)),te={created(){document.title="Uni-ISP"},data(){return{isImageLoading:!0,isPopup:!1,isPlayingVideo:!1,previews:{hdrRendering:{selectedItem:{id:"1",dataset:"FiveCam"},selectedModel:{name:"Input (LDR)",id:"input"},models:[{name:"Input (LDR)",id:"input"},{name:"CIE-XYZ Net",id:"cie-xyz-net"},{name:"CycleISP",id:"cycle-isp"},{name:"InvISP",id:"inv-isp"},{name:"ParamISP",id:"param-isp"},{name:"Uni-ISP (Ours)",id:"uni-isp"},{name:"GT (HDR)",id:"gt"}],images:[{id:"2",dataset:"FiveCam"},{id:"1",dataset:"FiveCam"}],root:"/pub-images/uni-isp/hdr-rendering"}}}},methods:{finishImageLoading(){this.isImageLoading=!1}}},se=Object.assign(te,{__name:"ProjectUniISPView",setup(d){return(a,o)=>(s(),n("div",L,[e("div",T,[F,e("div",D,[(s(!0),n(p,null,h(a.previews.hdrRendering.images,(t,c)=>(s(),_(f,{style:{cursor:"pointer"},backgroundCover:!0,class:u({"image-item":!0,selected:t.id==a.previews.hdrRendering.selectedItem.id}),backgroundImageUrl:a.previews.hdrRendering.root+"/"+t.id+"-gt.jpg",onClick:ne=>a.previews.hdrRendering.selectedItem=t},{default:g(()=>[e("div",V,[e("div",null,[e("span",B,"# "+r(c+1),1),z,G])])]),_:2},1032,["class","backgroundImageUrl","onClick"]))),256))]),X,e("div",A,[(s(!0),n(p,null,h(a.previews.hdrRendering.models,t=>(s(),n("a",{class:u("g-button g-hoverable pushable g-non-selectable g-relative"+(t.id==a.previews.hdrRendering.selectedModel.id?" g-accent":"")),style:{cursor:"pointer"},onClick:c=>{a.isImageLoading=!0,a.previews.hdrRendering.selectedModel=t}},r(t.name),11,H))),256))]),e("div",N,[e("div",null,[e("p",null,[e("strong",null,"Selected Item: "+r(a.previews.hdrRendering.selectedModel.name),1),Y,e("img",{class:"g-card",style:{width:"40%","max-width":"480px",margin:"20px"},onLoad:o[0]||(o[0]=t=>a.finishImageLoading()),src:a.previews.hdrRendering.root+"/"+a.previews.hdrRendering.selectedItem.id+"-"+a.previews.hdrRendering.selectedModel.id+".jpg"},null,40,E)])])]),$,b(w,{name:"scale",mode:"out-in"},{default:g(()=>[a.isPlayingVideo?(s(),n("div",K,Q)):(s(),n("div",O,[Z,e("p",q,[e("a",{class:"g-button g-hoverable pushable g-non-selectable g-relative",style:{cursor:"pointer",padding:"25px"},onClick:o[1]||(o[1]=t=>a.isPlayingVideo=!0)},[J,l(" Play Introduction Video ")])])]))]),_:1}),ee,ae,ie])]))}}),re=m(se,[["__scopeId","data-v-1b0781a9"]]);export{re as default};
